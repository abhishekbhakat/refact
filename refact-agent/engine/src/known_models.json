{
    "completion_models": {
        "starcoder": {
            "n_ctx": 4096,
            "scratchpad_patch": {
                "context_format": "starcoder",
                "rag_ratio": 0.5
            },
            "scratchpad": "FIM-PSM",
            "tokenizer": "hf://bigcode/starcoder2-3b",
            "similar_models": [
                "bigcode/starcoder",
                "bigcode/starcoderbase",
                "starcoder/15b/base",
                "starcoder/15b/plus",
                "starcoder/1b/base",
                "starcoder/3b/base",
                "starcoder/7b/base",
                "wizardcoder/15b",
                "starcoder/1b/vllm",
                "starcoder/3b/vllm",
                "starcoder/7b/vllm",
                "starcoder2/3b/base",
                "starcoder2/7b/base",
                "starcoder2/15b/base",
                "starcoder2/3b/vllm",
                "starcoder2/7b/vllm",
                "starcoder2/15b/vllm",
                "starcoder2/3b/neuron",
                "starcoder2/7b/neuron",
                "starcoder2/15b/neuron",
                "starcoder2/3b",
                "starcoder2/7b",
                "starcoder2/15b",
                "bigcode/starcoder2-3b",
                "bigcode/starcoder2-7b",
                "bigcode/starcoder2-15b"
            ]
        },
        "smallcloudai/Refact-1_6B-fim": {
            "n_ctx": 4096,
            "tokenizer": "hf://smallcloudai/Refact-1_6B-fim",
            "scratchpad": "FIM-SPM",
            "similar_models": [
                "Refact/1.6B",
                "Refact/1.6B/vllm"
            ]
        },
        "codellama/CodeLlama-13b-hf": {
            "n_ctx": 4096,
            "scratchpad_patch": {
                "fim_prefix": "<PRE>",
                "fim_suffix": "<SUF>",
                "fim_middle": "<MID>",
                "eot": "<EOT>",
                "eos": "</s>"
            },
            "scratchpad": "FIM-PSM",
            "tokenizer": "hf://codellama/CodeLlama-13b-hf",
            "similar_models": [
                "codellama/7b"
            ]
        },
        "deepseek-coder": {
            "n_ctx": 4096,
            "scratchpad_patch": {
                "fim_prefix": "<｜fim▁begin｜>",
                "fim_suffix": "<｜fim▁hole｜>",
                "fim_middle": "<｜fim▁end｜>",
                "eot": "<|EOT|>"
            },
            "scratchpad": "FIM-PSM",
            "tokenizer": "hf://deepseek-ai/deepseek-coder-1.3b-base",
            "similar_models": [
                "deepseek-coder/1.3b/base",
                "deepseek-coder/5.7b/mqa-base",
                "deepseek-coder/1.3b/vllm",
                "deepseek-coder/5.7b/vllm",
                "deepseek-ai/deepseek-coder-1.3b-base"
            ]
        },
        "stable/3b/code": {
            "n_ctx": 4096,
            "scratchpad": "FIM-PSM",
            "tokenizer": "hf://stabilityai/stable-code-3b",
            "similar_models": []
        },
        "llama3/8b/instruct": {
            "n_ctx": 8192,
            "scratchpad_patch": {
                "token_bos": "<|begin_of_text|>",
                "token_esc": "<|eot_id|>",
                "keyword_system": "<|start_header_id|>system<|end_header_id|>\n\n",
                "keyword_user": "<|start_header_id|>user<|end_header_id|>\n\n",
                "keyword_assistant": "<|start_header_id|>assistant<|end_header_id|>\n\n",
                "eot": "<|eot_id|>",
                "context_format": "chat",
                "rag_ratio": 0.5
            },
            "scratchpad": "REPLACE",
            "tokenizer": "hf://Xenova/llama3-tokenizer",
            "similar_models": [
                "llama3/8b/instruct/neuron",
                "llama3.1/8b/instruct",
                "llama3.2/3b/instruct",
                "llama3.2/1b/instruct"
            ]
        },
        "deepseek-coder/6.7b/instruct-finetune/vllm": {
            "n_ctx": 4096,
            "tokenizer": "hf://deepseek-ai/deepseek-coder-6.7b-instruct",
            "scratchpad": "REPLACE_PASSTHROUGH",
            "scratchpad_patch": {
                "context_format": "chat",
                "rag_ratio": 0.5
            }
        },
        "llama3/8b/instruct/vllm": {
            "n_ctx": 8192,
            "scratchpad": "REPLACE_PASSTHROUGH",
            "scratchpad_patch": {
                "context_format": "chat",
                "rag_ratio": 0.5
            },
            "tokenizer": "hf://Xenova/llama3-tokenizer",
            "similar_models": [
                "llama3.1/8b/instruct/vllm"
            ]
        },
        "llama3.2/1b/instruct/vllm": {
            "n_ctx": 16384,
            "scratchpad": "REPLACE_PASSTHROUGH",
            "scratchpad_patch": {
                "context_format": "chat",
                "rag_ratio": 0.5
            },
            "tokenizer": "hf://meta-llama/llama-3.2-1b-instruct",
            "similar_models": [
                "llama3.2/3b/instruct/vllm"
            ]
        },
        "qwen2.5/coder/1.5b/instruct/vllm": {
            "n_ctx": 32768,
            "scratchpad": "REPLACE_PASSTHROUGH",
            "scratchpad_patch": {
                "context_format": "chat",
                "rag_ratio": 0.5
            },
            "tokenizer": "hf://Qwen/Qwen2.5-Coder-1.5B-Instruct",
            "similar_models": [
                "qwen2.5/coder/3b/instruct/vllm",
                "qwen2.5/coder/7b/instruct/vllm",
                "qwen2.5/coder/14b/instruct/vllm",
                "qwen2.5/coder/32b/instruct/vllm",
                "qwen2.5/7b/instruct/vllm",
                "qwen2.5/14b/instruct/vllm",
                "qwen2.5/32b/instruct/vllm"
            ]
        },
        "gpt-4o": {
            "n_ctx": 128000,
            "scratchpad": "REPLACE_PASSTHROUGH",
            "scratchpad_patch": {
                "context_format": "chat",
                "rag_ratio": 0.5
            },
            "experimental": true,
            "tokenizer": "hf://Xenova/gpt-4o",
            "similar_models": [
                "gpt-4o-2024-05-13",
                "gpt-4o-2024-08-06",
                "gpt-4o-mini",
                "gpt-4o-mini-2024-07-18",
                "chatgpt-4o",
                "openai/gpt-4o",
                "openai/gpt-4o-2024-05-13",
                "openai/gpt-4o-2024-08-06",
                "openai/gpt-4o-mini",
                "openai/gpt-4o-mini-2024-07-18",
                "openai/chatgpt-4o"
            ]
        },
        "claude-3-sonnet": {
            "n_ctx": 200000,
            "scratchpad": "REPLACE_PASSTHROUGH",
            "scratchpad_patch": {
                "context_format": "chat",
                "rag_ratio": 0.5
            },
            "experimental": true,
            "tokenizer": "hf://Xenova/claude-tokenizer",
            "similar_models": [
                "claude-3-haiku",
                "claude-3-5-haiku",
                "claude-3-5-haiku-20241022",
                "claude-3-opus",
                "claude-3-5-sonnet",
                "claude-3-5-sonnet-20241022",
                "claude-3-7-sonnet",
                "claude-3-7-sonnet-20250219",
                "claude-3-7-sonnet-token-efficient-tools",
                "anthropic/claude-3-sonnet",
                "anthropic/claude-3-haiku",
                "anthropic/claude-3-5-haiku",
                "anthropic/claude-3-5-haiku-20241022",
                "anthropic/claude-3-opus",
                "anthropic/claude-3-5-sonnet",
                "anthropic/claude-3-5-sonnet-20241022",
                "anthropic/claude-3-7-sonnet",
                "anthropic/claude-3-7-sonnet-20250219",
                "claude-sonnet-4",
                "claude-sonnet-4-20250514",
                "claude-opus-4",
                "claude-opus-4-20250514",
                "anthropic/claude-sonnet-4-20250514",
                "anthropic/claude-opus-4-20250514"
            ]
        },
        "groq-llama-3.1-8b": {
            "n_ctx": 128000,
            "scratchpad": "REPLACE_PASSTHROUGH",
            "scratchpad_patch": {
                "context_format": "chat",
                "rag_ratio": 0.5
            },
            "tokenizer": "hf://Xenova/Meta-Llama-3.1-Tokenizer",
            "similar_models": [
                "groq-llama-3.1-70b",
                "groq-llama-3.2-1b",
                "groq-llama-3.2-3b",
                "groq-llama-3.2-11b-vision",
                "groq-llama-3.2-90b-vision"
            ]
        },
        "cerebras-llama3.1-8b": {
            "n_ctx": 8192,
            "scratchpad": "REPLACE_PASSTHROUGH",
            "scratchpad_patch": {
                "context_format": "chat",
                "rag_ratio": 0.5
            },
            "tokenizer": "hf://Xenova/Meta-Llama-3.1-Tokenizer",
            "similar_models": [
                "cerebras-llama3.1-70b"
            ]
        },
        "gemini-2.0-flash-exp": {
            "n_ctx": 128000,
            "supports_tools": true,
            "supports_multimodality": true,
            "supports_agent": false,
            "experimental": true,
            "scratchpad": "PASSTHROUGH",
            "tokenizer": "hf://Xenova/gemma2-tokenizer",
            "similar_models": [
                "gemini-1.5-flash",
                "gemini-1.5-flash-8b"
            ]
        },
        "gemini-1.5-pro": {
            "n_ctx": 128000,
            "supports_tools": true,
            "supports_multimodality": true,
            "supports_agent": true,
            "experimental": true,
            "scratchpad": "PASSTHROUGH",
            "tokenizer": "hf://Xenova/gemma2-tokenizer",
            "similar_models": [
                "gemini-2.0-exp-advanced",
                "gemini-2.5-pro"
            ]
        },
        "grok-beta": {
            "n_ctx": 128000,
            "supports_tools": true,
            "supports_agent": true,
            "experimental": true,
            "scratchpad": "REPLACE_PASSTHROUGH",
            "scratchpad_patch": {
                "context_format": "chat",
                "rag_ratio": 0.5
            },
            "tokenizer": "hf://Xenova/grok-1-tokenizer",
            "similar_models": [
                "grok-2-1212",
                "grok-2"
            ]
        },
        "grok-vision-beta": {
            "n_ctx": 8192,
            "experimental": true,
            "scratchpad": "REPLACE_PASSTHROUGH",
            "scratchpad_patch": {
                "context_format": "chat",
                "rag_ratio": 0.5
            },
            "tokenizer": "hf://Xenova/grok-1-tokenizer"
        },
        "grok-2-vision-1212": {
            "n_ctx": 32000,
            "experimental": true,
            "scratchpad": "REPLACE_PASSTHROUGH",
            "scratchpad_patch": {
                "context_format": "chat",
                "rag_ratio": 0.5
            },
            "tokenizer": "hf://Xenova/grok-1-tokenizer",
            "similar_models": [
                "grok-2-vision"
            ]
        },
        "deepseek-chat": {
            "n_ctx": 64000,
            "experimental": true,
            "scratchpad": "REPLACE_PASSTHROUGH",
            "scratchpad_patch": {
                "context_format": "chat",
                "rag_ratio": 0.5
            },
            "tokenizer": "hf://deepseek-ai/DeepSeek-V3"
        },
        "qwen2.5/coder/0.5b/instruct": {
            "n_ctx": 8192,
            "scratchpad_patch": {
                "token_bos": "",
                "token_esc": "",
                "keyword_system": "<|im_start|>system\n",
                "keyword_user": "<|im_start|>user\n",
                "keyword_assistant": "<|im_start|>assistant\n",
                "eot": "<|im_end|>",
                "context_format": "chat",
                "rag_ratio": 0.5
            },
            "scratchpad": "REPLACE",
            "tokenizer": "hf://Qwen/Qwen2.5-Coder-0.5B-Instruct",
            "similar_models": [
                "qwen2.5/coder/1.5b/instruct",
                "qwen2.5/coder/3b/instruct",
                "qwen2.5/coder/7b/instruct/gptq8bit",
                "qwen2.5/coder/7b/instruct",
                "qwen2.5/coder/14b/instruct/gptq8bit",
                "qwen2.5/coder/14b/instruct",
                "qwen2.5/coder/32b/instruct/gptq8bit",
                "qwen2.5/coder/32b/instruct"
            ]
        },
        "qwen2.5-coder-base": {
            "n_ctx": 8192,
            "scratchpad_patch": {
                "fim_prefix": "<|fim_prefix|>",
                "fim_suffix": "<|fim_suffix|>",
                "fim_middle": "<|fim_middle|>",
                "eot": "<|endoftext|>",
                "extra_stop_tokens": [
                    "<|repo_name|>",
                    "<|file_sep|>",
                    "<|fim_pad|>",
                    "<|cursor|>"
                ],
                "context_format": "qwen2.5",
                "rag_ratio": 0.5
            },
            "tokenizer": "hf://Qwen/Qwen2.5-Coder-0.5B",
            "scratchpad": "FIM-PSM",
            "similar_models": [
                "qwen2.5/coder/0.5b/base",
                "qwen2.5/coder/1.5b/base",
                "qwen2.5/coder/3b/base",
                "qwen2.5/coder/7b/base",
                "qwen2.5/coder/14b/base",
                "qwen2.5/coder/32b/base",
                "qwen2.5/coder/0.5b/base/vllm",
                "qwen2.5/coder/1.5b/base/vllm",
                "qwen2.5/coder/3b/base/vllm",
                "qwen2.5/coder/7b/base/vllm",
                "qwen2.5/coder/14b/base/vllm",
                "qwen2.5/coder/32b/base/vllm"
            ]
        }
    },
    "embedding_models": {
        "thenlper/gte-base": {
            "n_ctx": 512,
            "embedding_size": 768,
            "rejection_threshold": 0.25,
            "tokenizer": "hf://thenlper/gte-base"
        },
        "text-embedding-3-small": {
            "n_ctx": 8191,
            "embedding_size": 1536,
            "rejection_threshold": 0.63,
            "similar_models": [
                "openai/text-embedding-3-small"
            ],
            "tokenizer": "hf://Xenova/text-embedding-ada-002"
        },
        "gemini-embedding-exp": {
            "n_ctx": 8192,
            "embedding_size": 3072,
            "similar_models": [
                "gemini-embedding-exp-03-07"
            ],
            "tokenizer": "hf://Xenova/gemma2-tokenizer"
        },
        "models/text-embedding-004": {
            "n_ctx": 2048,
            "embedding_size": 768,
            "similar_models": [],
            "tokenizer": "hf://Xenova/gemma2-tokenizer"
        }
    },
    "comments": [
        "gemini and gemma bear the same tokenizer",
        "according to https://medium.com/google-cloud/a-gemini-and-gemma-tokenizer-in-java-e18831ac9677",
        "downloadable tokenizer.json does not exist for gemini, the only precise way is to use web-requests",

        "XAI WARNING: tokenizer is non-precise as there's no publicly available tokenizer for these models",
        "XAI says that for exact same model different tokenizers could be used",
        "therefore, using tokenizer for grok-1 which may or may not provide proximate enough results"
    ]
}
